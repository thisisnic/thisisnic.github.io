<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Nic Crane</title>
    <link>/post/</link>
    <description>Recent content in Posts on Nic Crane</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-uk</language>
    <lastBuildDate>Mon, 21 Nov 2022 00:00:00 +0000</lastBuildDate><atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Type inference in readr and arrow</title>
      <link>/2022/11/21/type-inference-in-readr-and-arrow/</link>
      <pubDate>Mon, 21 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>/2022/11/21/type-inference-in-readr-and-arrow/</guid>
      <description>The CSV format is widely used in data science, and at its best works well as a simple human-readable format that is widely known and understood. The simplicity of CSVs though, as a basic text format also has its drawbacks. One is that it contains no information about data types of its columns, and if you’re working with CSVs in an application more complex than a text editor, those data types must be inferred by whatever is reading the data.</description>
    </item>
    
    <item>
      <title>Arrow New Feature Showcase: `show_exec_plan()`</title>
      <link>/2022/08/26/arrow-new-feature-showcase-show-exec-plan/</link>
      <pubDate>Fri, 26 Aug 2022 00:00:00 +0000</pubDate>
      
      <guid>/2022/08/26/arrow-new-feature-showcase-show-exec-plan/</guid>
      <description>The arrow package allows you to take advantage of the power of the Acero execution engine for data manipulation and analysis. The code in arrow provides bindings to dplyr verbs and tidyverse functions, so that you can use these interfaces without having to understand the inner workings of Acero. But what if you actually want to know more?
In the latest release of arrow, version 9.0.0, the show_exec_plan() function is introduced.</description>
    </item>
    
    <item>
      <title>Customising pkgdown with a version selector</title>
      <link>/2022/04/15/customising-pkgdown-with-a-version-selector/</link>
      <pubDate>Fri, 15 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>/2022/04/15/customising-pkgdown-with-a-version-selector/</guid>
      <description>One of the things I&amp;rsquo;ve been working on lately is implementing a version selector for the Arrow pkgdown site, so that users can browse to previous versions of the documentation. In this post, I discuss the problem and the implemented solution.
The problem I was excited to work on this feature as its importance is clear to me from my consulting days; I&amp;rsquo;ve worked with many organisations who have had to lock down versions of R packages they allow employees to install, and so upgrading to the latest version isn&amp;rsquo;t an option.</description>
    </item>
    
    <item>
      <title>Error chaining</title>
      <link>/2022/04/09/error-chaining/</link>
      <pubDate>Sat, 09 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>/2022/04/09/error-chaining/</guid>
      <description>In this post, I’m going to talk about error chaining - overriding default error messages to add further hints for a user. I had a need to learn this while working on Arrow on code which resulted in a C++ error message, to which I wanted to add extra hints relevant to R users. I’ve used a toy example below to make it more straightforward to demonstrate.
Introduction Let’s imagine I work in the HR department of the UK’s number 1 employer of cats.</description>
    </item>
    
    <item>
      <title>Open Source Developer Apprenticeship - 9 months in</title>
      <link>/2022/01/23/open-source-developer-apprenticeship-9-months-in/</link>
      <pubDate>Sun, 23 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>/2022/01/23/open-source-developer-apprenticeship-9-months-in/</guid>
      <description>I’ve been meaning to blog for ages but have been so wrapped up in project things and getting nerd-sniped. Here’s a bit about the last six months.
Open-ended role I’m doing a better job of adapting to the environment of total freedom within the role. My team has quarterly initiatives to complete, but otherwise, my job is just to “be an open-source maintainer” and do whatever that entails, with colleagues occasionally asking me to get involved with specific pieces of work.</description>
    </item>
    
    <item>
      <title>My First 3 Months at Ursa Computing</title>
      <link>/2021/07/05/my-first-3-months-at-ursa-computing/</link>
      <pubDate>Mon, 05 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>/2021/07/05/my-first-3-months-at-ursa-computing/</guid>
      <description>The last time I blogged, I mentioned not being comfortable with the open-ended-ness of everything, but I was confident that in time I would adjust and start to see the benefits. And that’s precisely what has happened.
One habit I’ve had for a very long time is being possessed by a real sense of urgency, and it’s a double-edged sword. Sure, I get things done, but getting something working without necessarily knowing why it’s working makes for the appearance of being highly productive, without developing a deep understanding that can later transfer to other areas.</description>
    </item>
    
    <item>
      <title>R package documentation - what makes a good example?</title>
      <link>/2021/05/18/r-package-documentation-what-makes-a-good-example/</link>
      <pubDate>Tue, 18 May 2021 00:00:00 +0000</pubDate>
      
      <guid>/2021/05/18/r-package-documentation-what-makes-a-good-example/</guid>
      <description>I&amp;rsquo;m currently working on adding to the documentation of the arrow R package, and I&amp;rsquo;ve started thinking about the qualities of good examples. Specifically, I&amp;rsquo;m referring to the examples included as part of function documentation. In my experience, the best way for me to achieve rapid familiarity with an R function I haven&amp;rsquo;t worked with before, or understand how to use a function about which I already understand the basics, is by having example code that I can run.</description>
    </item>
    
    <item>
      <title>My First Month at Ursa Computing</title>
      <link>/2021/05/13/my-first-month-at-ursa-computing/</link>
      <pubDate>Thu, 13 May 2021 00:00:00 +0000</pubDate>
      
      <guid>/2021/05/13/my-first-month-at-ursa-computing/</guid>
      <description>I&amp;rsquo;ve now been working at Ursa Computing on Apache Arrow for just over a month, and thought it would be a good time to write a blog post about my experiences over the past month.
So when I found out I got the apprenticeship, I will admit, I shrieked with joy. It was a similar noise to the one I made when I found out that my talk had been accepted for rstudio::conf 2019.</description>
    </item>
    
    <item>
      <title>This Fortnight on the Arrow Dev Mailing List</title>
      <link>/2021/05/10/this-fortnight-on-the-arrow-dev-mailing-list/</link>
      <pubDate>Mon, 10 May 2021 00:00:00 +0000</pubDate>
      
      <guid>/2021/05/10/this-fortnight-on-the-arrow-dev-mailing-list/</guid>
      <description>New PMC members Benjamin Kietzman has joined the Arrow Project Management Committee.
New committers Ian Cook, Jonanthan Keane, and Daniël Heres were added as new committers
OpenTelemetry Discussion around integrating OpenTelemetry (a library for distrubuted tracing) into the C++ codebase. OpenTelemetry allows instrumentation - being able to better make us of telemetry data for diagnosing errors and writing trace information.
Interval data type Discussion around a proposal to introduce an interval (i.</description>
    </item>
    
    <item>
      <title>Definitions #1</title>
      <link>/2021/04/27/definitions-1/</link>
      <pubDate>Tue, 27 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>/2021/04/27/definitions-1/</guid>
      <description>This post contains answers to a number of questions I had when reading through the Apache Arrow dev mailing list. In future posts I&amp;rsquo;ll look up how to properly use footnotes in markdown!
What is DataFusion?  DataFusion is an attempt at building a modern distributed compute platform in Rust, leveraging Apache Arrow as the memory model.
 What is Ballista?  Ballista is a distributed compute platform primarily implemented in Rust, powered by Apache Arrow.</description>
    </item>
    
    <item>
      <title>This Week on the Arrow Dev Mailing List</title>
      <link>/2021/04/27/this-week-on-the-arrow-dev-mailing-list/</link>
      <pubDate>Tue, 27 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>/2021/04/27/this-week-on-the-arrow-dev-mailing-list/</guid>
      <description>Inspired by &amp;ldquo;This Week in Ballista&amp;rdquo;, and my desire to keep up-to-date with everything happening in Arrow, here&amp;rsquo;s my first &amp;ldquo;This Week in Arrow&amp;rdquo;, summarising the main occurrences on the dev mailing list from 20th - 27th April 2021.
Release candidate 1 There were votes on a few release candidates. RC1 was blocked due to a number of issues. There was an update which changed the default memory pool to prefer mimalloc instead of jemalloc on MacOs, as this had been shown to lead to better peformance on macOS.</description>
    </item>
    
    <item>
      <title>Examining C&#43;&#43; syntax - RecordBatch::SelectColumns</title>
      <link>/2021/04/21/examining-c-plus-plus-syntax-recordbatch-selectcolumns/</link>
      <pubDate>Wed, 21 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>/2021/04/21/examining-c-plus-plus-syntax-recordbatch-selectcolumns/</guid>
      <description>I’m approaching learning C++ by taking both a top-down and bottom-up approach, looking at tutorials and learning the basics whilst also working with existing C++ code in the Arrow codebase.
I wanted to take a snippet of code from something that I’ve been working on an enhance my understanding of it. I posted this on Slack, and my colleagues were generous with their time and knowledge, helping me check my understanding, which I’m now going to outline below.</description>
    </item>
    
    <item>
      <title>Why is eval parse bad?</title>
      <link>/2021/04/20/why-is-eval-parse-bad/</link>
      <pubDate>Tue, 20 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>/2021/04/20/why-is-eval-parse-bad/</guid>
      <description>I was writing Arrow bindings for na.omit and needed a way of applying is.na to every column of a table at once. I’d originally implemented using dplyr::filter, but had failed to realise that Arrow only suggests dplyr but doesn’t import it, and so needed to refactor it.
Table objects in Arrow have a Filter method, and I knew that a naive implementation would be a for loop which iteratively called Table$Filter(!</description>
    </item>
    
    <item>
      <title>Three Valued Logic</title>
      <link>/2021/04/17/three-valued-logic/</link>
      <pubDate>Sat, 17 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>/2021/04/17/three-valued-logic/</guid>
      <description>This week I was writing Arrow bindings for some R functions and came across a concept that was new to me: three-valued logic.
I encountered this when working out the expected behaviour of the functions any and all which are used for aggregation of boolean/logical values.
If I have a vector without any NA values, the behaviour of these functions is pretty straightforward. In the example below, vec &amp;gt; 3 evaluates to FALSE FALSE FALSE TRUE TRUE and so a call to any() results in TRUE and a call to all() results in FALSE.</description>
    </item>
    
    <item>
      <title>UseR!2019: A Shiny Perspective</title>
      <link>/2019/07/28/user-2019/</link>
      <pubDate>Sun, 28 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/07/28/user-2019/</guid>
      <description>UseR!2019 UseR!2019 was a fantastic conference. I’ve previously attended RStudio Conference and EARL, both of which are very different conferences. I’ve enjoyed all three, and especially like how they each bring something different to the R conference playing field.
I mainly work in Shiny, and so most of this post will be including some of my Shiny-focussed highlights, with a few other special mentions.
The conference kicked off with a Tidyverse Developer Day, organised by RStudio.</description>
    </item>
    
    <item>
      <title>Iterating with names</title>
      <link>/2018/12/19/iterating-with-names/</link>
      <pubDate>Wed, 19 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/12/19/iterating-with-names/</guid>
      <description>title: ‘Iterating with names’  author: ’’  date: ‘2018-12-19’  slug: iterating-with-names  categories: [  ‘R’  ]  tags: [‘tidyverse’, ‘purrr’]  type: post    The Problem I’ve come across this problem a few times lately, when I’ve wanted to iterate through some sort of named list or vector, and use both the name and value in each iteration.
To illustrate, here’s a vector, which I have creatively named myvec.</description>
    </item>
    
    <item>
      <title>Ten Steps to Becoming a Tidyverse Contributor</title>
      <link>/2018/11/28/ten-steps-to-becoming-a-tidyverse-contributor/</link>
      <pubDate>Wed, 28 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/11/28/ten-steps-to-becoming-a-tidyverse-contributor/</guid>
      <description>This year has been a crazy whirlwind for me – I moved job once, moved house 3 times, co-authored a course on Data Camp, got invited by a former colleague to assist with a workshop at rstudio::conf 2019, was accepted to present at the very same conference, and became a minor contributor to the tidyverse. In this blog post I’ll talk about reasons for contributing and then walk through the steps I took to help guide others.</description>
    </item>
    
    <item>
      <title>Scraping rstudio::conf 2018 Abstracts</title>
      <link>/2018/08/22/scraping-rstudio-conf-2018-abstracts/</link>
      <pubDate>Wed, 22 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/22/scraping-rstudio-conf-2018-abstracts/</guid>
      <description>RStudio Conference 2019 takes place in January 2019, and this week RStudio put out a call for contributed talks and e-posters. Though I was eager to browse previous years’ abstracts for inspiration, I couldn’t find them all in one place, and so I decided to use one of my favourite R packages, rvest, to do some web scraping to grab the content.
My main aim was to find all of the abstracts for the contributed talks only from 2018.</description>
    </item>
    
    <item>
      <title>Comparing R packages using packagemetrics</title>
      <link>/2018/07/31/comparing-r-packages-using-packagemetrics/</link>
      <pubDate>Tue, 31 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/07/31/comparing-r-packages-using-packagemetrics/</guid>
      <description>A colleague asked for my opinion on 2 packages; loggit and futile.logger. Whilst I have used futile.logger before, I hadn’t used loggit and so used the metrics of the package to evaluate the package itself.
The packagemetrics package allows us to generate a number of metrics about a package, so we can compare them. The first thing I do is call package_list_metrics() to get metrics about thesetwo packages. I’ve changed the shape of the table, just so it’s easier to read in this blog post.</description>
    </item>
    
    <item>
      <title>How do I make my own dplyr-style functions?</title>
      <link>/2018/04/16/how-do-i-make-my-own-dplyr-style-functions/</link>
      <pubDate>Mon, 16 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/16/how-do-i-make-my-own-dplyr-style-functions/</guid>
      <description>In this series of blog posts introducing tidy eval, we’ve been looking at why tidy eval is important, and terms like “quotation” and “quasiquotation”.
The next step is to look at how we can write our own dplyr-style functions in R.
This post will look at the following terms and functions:
 quosures quo() enquo()  What is a quosure? Quosures are a topic which come up frequently when talking about tidy eval.</description>
    </item>
    
    <item>
      <title>What the heck is quasiquotation?</title>
      <link>/2018/03/31/what-the-heck-is-quasiquotation/</link>
      <pubDate>Sat, 31 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/03/31/what-the-heck-is-quasiquotation/</guid>
      <description>In a previous entry, I introduced the concept of tidy eval. If you’re completely new to tidy eval and haven’t read that post yet, I’d suggest you go back to it before continuing, as this post will build upon the concepts I discussed there.
To recap, tidy eval refers to the ‘special’ type of evaluation used by dplyr functions. Whereas in base R, you have to refer the data frame in question if you want to returns particular rows, this is not the case with dplyr functions.</description>
    </item>
    
    <item>
      <title>What is tidy eval and why should I care?</title>
      <link>/2018/03/29/what-is-tidy-eval-and-why-should-i-care/</link>
      <pubDate>Thu, 29 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/03/29/what-is-tidy-eval-and-why-should-i-care/</guid>
      <description>I’m going to begin this post somewhat backwards, and start with the conclusion: tidy eval is important to anyone who writes R functions and uses dplyr and/or tidyr.
I’m going to load a couple of packages, and then show you exactly why.
library(dplyr) library(rlang) Data wrangling with base R Here’s an example function I have written in base R. Its purpose is to take a data set, and extract values from a single column that match a specific value, with both input and output both being in data frame format.</description>
    </item>
    
    <item>
      <title>Using Tidy Eval with dplyr::filter</title>
      <link>/2018/03/27/using-tidy-eval-with-dplyr-filter/</link>
      <pubDate>Tue, 27 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/03/27/using-tidy-eval-with-dplyr-filter/</guid>
      <description>I previously blogged about using tidy eval with dplyr::mutate, and found that post handy to refer back to. I still haven’t got round to having an in-depth look at the principles of tidy eval, so instead I’m continuing to explore problems as and when they come up. In this post, I’ll be taking a look at using tidy eval with dplyr::filter. Once again, I’ll be using the iris dataset to create examples that should be simple to follow.</description>
    </item>
    
    <item>
      <title>Exploring Tidy Eval at a Snail&#39;s Pace</title>
      <link>/2018/02/20/exploring-tidy-eval-snails-pace/</link>
      <pubDate>Tue, 20 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/02/20/exploring-tidy-eval-snails-pace/</guid>
      <description>I recently attended rstudio::conf, with my favourite talks being those which taught me new things that I am going to use in my day-to-day work. I attended and enjoyed Hadley Wickham’s talk, ‘Tidy eval: programming with dplyr, tidyr, and ggplot2’, although got sidetracked trying to keep up typing whilst listening.
When I’m delivering training courses, this is the one thing I advise all attendees not to do - it’s so easy to miss important points whilst running code.</description>
    </item>
    
    <item>
      <title>Basic Spark Part 1 - Umm, remind me about big data please?</title>
      <link>/2018/02/02/basic-spark-part-1/</link>
      <pubDate>Fri, 02 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/02/02/basic-spark-part-1/</guid>
      <description>When I started my career in data science, I was in the common position of having familiarity with technologies like R, Python, and SQL, but much less with big data technologies. I remember feeling intimidated by big data; there were lots of different technologies named after animals or making some sort of pun I wasn’t clued up enough to understand.
Flash forward 18 months and with experience, some parts of the big data landscape felt a bit more familiar.</description>
    </item>
    
    <item>
      <title>Pop-up to confirm action in Shiny</title>
      <link>/2016/08/16/pop-up-to-confirm-action-in-shiny/</link>
      <pubDate>Tue, 16 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>/2016/08/16/pop-up-to-confirm-action-in-shiny/</guid>
      <description>It’s a gorgeous evening in Bath tonight, and my evening has been improved by finding a free table outside at the pub, a large glass of Sauvignon Blanc, and working out how to include a JavaScript confirmation box in Shiny. Here, I’m using Shiny dashboard, although this methodology will work fine with other UI layouts.
In the UI file, near the top of the dashboardBody , call tags$head and tags$script to give the source of the JavaScript file:</description>
    </item>
    
    <item>
      <title>Getting started with Leaflet in Shiny - interactive map apps</title>
      <link>/2016/04/28/getting-started-with-leaflet-in-shiny-interactive-map-apps/</link>
      <pubDate>Thu, 28 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>/2016/04/28/getting-started-with-leaflet-in-shiny-interactive-map-apps/</guid>
      <description>Lately I’ve been enjoying learning how to use Shiny, and experimenting with making a fairly basic app, and wanted to develop my skills further. I’d been looking at an example app from the Shiny website which shows live bus locations in the US, refreshing at short intervals. It looked fairly complex at first, so I was pretty happy when, within 48 hours I’d managed to recreate something of similar complexity, so here’s your guide on how you can quickly get up to speed using interactive reactive maps in Shiny.</description>
    </item>
    
  </channel>
</rss>
